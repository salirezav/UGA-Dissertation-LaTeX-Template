@article{10.1148/ryai.2020190195,
  author  = {Yan, Wenjun and Huang, Lu and Xia, Liming and Gu, Shengjia and Yan, Fuhua and Wang, Yuanyuan and Tao, Qian},
  doi     = {10.1148/ryai.2020190195},
  eprint  = {10.1148/ryai.2020190195},
  journal = {Radiology: Artificial Intelligence},
  note    = {PMID: 33937833},
  number  = 4,
  pages   = {e190195},
  title   = {MRI Manufacturer Shift and Adaptation: Increasing the           Generalizability of Deep Learning Segmentation for MR Images Acquired with           Different Scanners},
  url     = {10.1148/ryai.2020190195},
  volume  = 2,
  year    = 2020
}
@article{10.3389/fcvm.2020.00105,
  abstract = {Background: Convolutional neural network (CNN) based segmentation methods provide an efficient and automated way for clinicians to assess the structure and function of the heart in cardiac MR images. While CNNs can generally perform the segmentation tasks with high accuracy when training and test images come from the same domain (e.g., same scanner or site), their performance often degrades dramatically on images from different scanners or clinical sites.Methods: We propose a simple yet effective way for improving the network generalization ability by carefully designing data normalization and augmentation strategies to accommodate common scenarios in multi-site, multi-scanner clinical imaging data sets. We demonstrate that a neural network trained on a single-site single-scanner dataset from the UK Biobank can be successfully applied to segmenting cardiac MR images across different sites and different scanners without substantial loss of accuracy. Specifically, the method was trained on a large set of 3,975 subjects from the UK Biobank. It was then directly tested on 600 different subjects from the UK Biobank for intra-domain testing and two other sets for cross-domain testing: the ACDC dataset (100 subjects, 1 site, 2 scanners) and the BSCMR-AS dataset (599 subjects, 6 sites, 9 scanners).Results: The proposed method produces promising segmentation results on the UK Biobank test set which are comparable to previously reported values in the literature, while also performing well on cross-domain test sets, achieving a mean Dice metric of 0.90 for the left ventricle, 0.81 for the myocardium, and 0.82 for the right ventricle on the ACDC dataset; and 0.89 for the left ventricle, 0.83 for the myocardium on the BSCMR-AS dataset.Conclusions: The proposed method offers a potential solution to improve CNN-based model generalizability for the cross-scanner and cross-site cardiac MR image segmentation task.},
  author   = {Chen, Chen and Bai, Wenjia and Davies, Rhodri H. and Bhuva, Anish N. and Manisty, Charlotte H. and Augusto, Joao B. and Moon, James C and Aung, Nay and Lee, Aaron M. and Sanghvi, Mihir M. and Fung, Kenneth and Paiva, Jose Miguel and Petersen, Steffen E. and Lukaschuk, Elena and Piechnik, Stefan K. and Neubauer, Stefan and Rueckert, Daniel},
  doi      = {https://doi.org/10.3389/fcvm.2020.00105},
  issn     = {2297-055X},
  journal  = {Frontiers in Cardiovascular Medicine},
  title    = {Improving the Generalizability of Convolutional Neural Network-Based Segmentation on CMR Images},
  url      = {https://www.frontiersin.org/articles/10.3389/fcvm.2020.00105},
  volume   = 7,
  year     = 2020
}
@inproceedings{anonymous2022,
  author    = {Anonymous anonymous},
  booktitle = {SciPy},
  pages     = {******},
  title     = {********************************************************},
  year      = 2022
}
@article{article1,
  archiveprefix = {arXiv},
  author        = {Chris Whitmire and Brij Rokad and Caleb Crumley},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1905-06012},
  eprint        = {1905.06012},
  journal       = {CoRR},
  timestamp     = {Tue, 28 May 2019 12:48:08 +0200},
  title         = {Origami Inspired Solar Panel Design},
  url           = {http://arxiv.org/abs/1905.06012},
  volume        = {abs/1905.06012},
  year          = 2019
}
@book{article2,
  author      = {Navaud, Guillaume},
  hyphenation = {spanish},
  isbn        = 9782600014038,
  language    = {spanish},
  publisher   = {Droz},
  series      = {Travaux d'humanisme et renaissance: no 478},
  title       = {Persona : le théâtre comme métaphore théorique de Socrate à Shakespeare.},
  url         = {http://proxy-remote.galib.uga.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=cat06564a&AN=uga.9939271873902959&site=eds-live},
  year        = 2011
}
@article{biswas2023polyp,
  author  = {Biswas, Risab},
  journal = {arXiv preprint arXiv:2308.06623},
  title   = {Polyp-sam++: Can a text guided sam perform better for polyp segmentation?},
  year    = 2023
}
@article{bolya2023window,
  author  = {Bolya, Daniel and Ryali, Chaitanya and Hoffman, Judy and Feichtenhofer, Christoph},
  journal = {arXiv preprint arXiv:2311.05613},
  title   = {Window attention is bugged: how not to interpolate position embeddings},
  year    = 2023
}
@article{breiman2001random,
  author    = {Breiman, Leo},
  journal   = {Machine learning},
  pages     = {5--32},
  publisher = {Springer},
  title     = {Random forests},
  volume    = 45,
  year      = 2001
}
@inproceedings{cai2018cascade,
  author    = {Cai, Zhaowei and Vasconcelos, Nuno},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {6154--6162},
  title     = {Cascade r-cnn: Delving into high quality object detection},
  year      = 2018
}
@inproceedings{cao2022swin,
  author       = {Cao, Hu and Wang, Yueyue and Chen, Joy and Jiang, Dongsheng and Zhang, Xiaopeng and Tian, Qi and Wang, Manning},
  booktitle    = {European conference on computer vision},
  organization = {Springer},
  pages        = {205--218},
  title        = {Swin-unet: Unet-like pure transformer for medical image segmentation},
  year         = 2022
}
@inproceedings{cciccek20163d,
  author       = {{\c{C}}i{\c{c}}ek, {\"O}zg{\"u}n and Abdulkadir, Ahmed and Lienkamp, Soeren S and Brox, Thomas and Ronneberger, Olaf},
  booktitle    = {Medical Image Computing and Computer-Assisted Intervention--MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part II 19},
  organization = {Springer},
  pages        = {424--432},
  title        = {3D U-Net: learning dense volumetric segmentation from sparse annotation},
  year         = 2016
}
@article{chen2020big,
  author  = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  journal = {Advances in neural information processing systems},
  pages   = {22243--22255},
  title   = {Big self-supervised models are strong semi-supervised learners},
  volume  = 33,
  year    = 2020
}
@article{chen2020improved,
  author  = {Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal = {arXiv preprint arXiv:2003.04297},
  title   = {Improved baselines with momentum contrastive learning},
  year    = 2020
}
@inproceedings{chen2020simple,
  author       = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle    = {International conference on machine learning},
  organization = {PmLR},
  pages        = {1597--1607},
  title        = {A simple framework for contrastive learning of visual representations},
  year         = 2020
}
@article{chen2021transunet,
  author  = {Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L and Zhou, Yuyin},
  journal = {arXiv preprint arXiv:2102.04306},
  title   = {Transunet: Transformers make strong encoders for medical image segmentation},
  year    = 2021
}
@article{cortes1995support,
  author    = {Cortes, Corinna and Vapnik, Vladimir},
  journal   = {Machine learning},
  pages     = {273--297},
  publisher = {Springer},
  title     = {Support-vector networks},
  volume    = 20,
  year      = 1995
}
@article{croitoru2019unsupervised,
  author    = {Croitoru, Ioana and Bogolin, Simion-Vlad and Leordeanu, Marius},
  journal   = {International Journal of Computer Vision},
  pages     = {1279--1302},
  publisher = {Springer},
  title     = {Unsupervised learning of foreground object segmentation},
  volume    = 127,
  year      = 2019
}
@inproceedings{de2023domain,
  author       = {de Dumast, Priscille and Cuadra, Meritxell Bach},
  booktitle    = {2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)},
  organization = {IEEE},
  pages        = {1--5},
  title        = {Domain Generalization in Fetal Brain MRI Segmentation with Multi-Reconstruction Augmentation},
  year         = 2023
}
@article{doretto2003dynamic,
  author    = {Doretto, Gianfranco and Chiuso, Alessandro and Wu, Ying Nian and Soatto, Stefano},
  doi       = {https://doi.org/10.1023/A:1021669406132},
  journal   = {International journal of computer vision},
  pages     = {91--109},
  publisher = {Springer},
  title     = {Dynamic textures},
  volume    = 51,
  year      = 2003
}
@article{fazeli2020automated,
  author    = {Fazeli, Elnaz and Roy, Nathan H and Follain, Gautier and Laine, Romain F and von Chamier, Lucas and H{\"a}nninen, Pekka E and Eriksson, John E and Tinevez, Jean-Yves and Jacquemet, Guillaume},
  doi       = {10.12688/f1000research.27019.1},
  journal   = {F1000Research},
  publisher = {Faculty of 1000 Ltd},
  title     = {Automated cell tracking using StarDist and TrackMate},
  volume    = 9,
  year      = 2020
}
@inproceedings{fazli2018toward,
  author       = {Fazli, Mojtaba S and Vella, Stephen A and Moreno, Silvia NJ and Ward, Gary E and Quinn, Shannon P},
  booktitle    = {2018 IEEE International Conference on Big Data (Big Data)},
  doi          = {10.1109/BigData.2018.8622403},
  organization = {IEEE},
  pages        = {3217--3225},
  title        = {Toward simple \& scalable 3D cell tracking},
  year         = 2018
}
}
@inproceedings{fazli2018unsupervised,
  author       = {Fazli, Mojtaba S and Velia, Stephen A and Moreno, Silvia NJ and Quinn, Shannon},
  booktitle    = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
  doi          = {10.1109/isbi.2018.8363735},
  organization = {IEEE},
  pages        = {981--984},
  title        = {Unsupervised discovery of toxoplasma gondii motility phenotypes},
  year         = 2018
}
@inproceedings{fazli2019lightweight,
  author       = {Fazli, Mojtaba Sedigh and Stadler, Rachel V and Alaila, BahaaEddin and Vella, Stephen A and Moreno, Silvia NJ and Ward, Gary E and Quinn, Shannon},
  booktitle    = {2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
  doi          = {10.1109/dsaa.2019.00056},
  organization = {IEEE},
  pages        = {412--421},
  title        = {Lightweight and scalable particle tracking and motion clustering of 3D cell trajectories},
  year         = 2019
}
@article{goodfellow2014generative,
  author  = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  doi     = {10.48550/arXiv.1406.2661},
  journal = {Advances in neural information processing systems},
  title   = {Generative adversarial nets},
  volume  = 27,
  year    = 2014
}
@article{gu2021domain,
  author    = {Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal   = {ACM Transactions on Computing for Healthcare (HEALTH)},
  number    = 1,
  pages     = {1--23},
  publisher = {ACM New York, NY},
  title     = {Domain-specific language model pretraining for biomedical natural language processing},
  volume    = 3,
  year      = 2021
}
@article{Hansen2021-fd,
  author  = {Hansen, Jan Niklas and Rassmann, Sebastian and St{\"u}ven, Birthe and Jurisch-Yaksi, Nathalie and Wachten, Dagmar},
  doi     = {https://doi.org/10.1140/epje/s10189-021-00031-y},
  journal = {The European Physical Journal E},
  month   = {mar},
  number  = 2,
  pages   = 18,
  title   = {{CiliaQ}: a simple, open-source software for automated quantification of ciliary morphology and fluorescence in 2D, 3D, and {4D} images},
  volume  = 44,
  year    = 2021
}
@inproceedings{hatamizadeh2022unetr,
  author    = {Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger R and Xu, Daguang},
  booktitle = {Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages     = {574--584},
  title     = {Unetr: Transformers for 3d medical image segmentation},
  year      = 2022
}
@misc{he2018maskrcnn,
  archiveprefix = {arXiv},
  author        = {Kaiming He and Georgia Gkioxari and Piotr Dollár and Ross Girshick},
  eprint        = {1703.06870},
  primaryclass  = {cs.CV},
  title         = {Mask R-CNN},
  url           = {https://arxiv.org/abs/1703.06870},
  year          = 2018
}
@inproceedings{he2020momentum,
  author    = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {9729--9738},
  title     = {Momentum contrast for unsupervised visual representation learning},
  year      = 2020
}
@inproceedings{he2022masked,
  author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {16000--16009},
  title     = {Masked autoencoders are scalable vision learners},
  year      = 2022
}
@inbook{Hoyer-Fender2013,
  address   = {Dordrecht},
  author    = {Hoyer-Fender, Sigrid},
  booktitle = {Cilia and Nervous System Development and Function},
  doi       = {10.1007/978-94-007-5808-7_1},
  editor    = {Tucker, Kerry L.  and Caspary, Tamara},
  isbn      = {978-94-007-5808-7},
  pages     = {1--53},
  publisher = {Springer Netherlands},
  title     = {Primary and Motile Cilia: Their Ultrastructure and Ciliogenesis},
  url       = {https://doi.org/10.1007/978-94-007-5808-7_1},
  year      = 2013
}
@article{https://doi.org/10.1002/ppul.24078,
  author   = {Kempeneers, Céline and Chilvers, Mark A.},
  doi      = {https://doi.org/10.1002/ppul.24078},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ppul.24078},
  journal  = {Pediatric Pulmonology},
  keywords = {cilia, ciliopathie, motile cilia, non-motile cilia, primary ciliary dyskinesia, respiratory cilia},
  number   = 8,
  pages    = {1122--1129},
  title    = {To beat, or not to beat, that is question! The spectrum of ciliopathies},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ppul.24078},
  volume   = 53,
  year     = 2018
}
@article{hu2022lora,
  author  = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal = {ICLR},
  number  = 2,
  pages   = 3,
  title   = {Lora: Low-rank adaptation of large language models.},
  volume  = 1,
  year    = 2022
}
@article{huang2022multi,
  author  = {Huang, Ziqi and Lin, Li and Cheng, Pujin and Peng, Linkai and Tang, Xiaoying},
  journal = {arXiv preprint arXiv:2203.04586},
  title   = {Multi-modal brain tumor segmentation via missing modality synthesis and modality-level attention fusion},
  year    = 2022
}
@article{huang2024learning,
  author  = {Huang, Jiaxing and Jiang, Kai and Zhang, Jingyi and Qiu, Han and Lu, Lewei and Lu, Shijian and Xing, Eric},
  journal = {arXiv preprint arXiv:2401.04651},
  title   = {Learning to prompt segment anything models},
  year    = 2024
}
@inproceedings{huang2024segment,
  author    = {Huang, Xiaoke and Wang, Jianfeng and Tang, Yansong and Zhang, Zheng and Hu, Han and Lu, Jiwen and Wang, Lijuan and Liu, Zicheng},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {13405--13417},
  title     = {Segment and caption anything},
  year      = 2024
}
@misc{hutchinson2017overcoming,
  archiveprefix = {arXiv},
  author        = {Maxwell L. Hutchinson and Erin Antono and Brenna M. Gibbons and Sean Paradiso and Julia Ling and Bryce Meredig},
  doi           = {https://doi.org/10.48550/arXiv.1711.05099},
  eprint        = {1711.05099},
  primaryclass  = {cs.LG},
  title         = {Overcoming data scarcity with transfer learning},
  year          = 2017
}
@inproceedings{Hyndman2007HigherorderAM,
  author    = {Hyndman, Midori and Jepson, Allan D and Fleet, David J},
  booktitle = {BMVC},
  pages     = {1--10},
  title     = {Higher-order Autoregressive Models for Dynamic Textures.},
  year      = 2007
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%    AIM 3    %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@misc{Iakubovskii:2019,
  author       = {Pavel Iakubovskii},
  howpublished = {\url{https://github.com/qubvel/segmentation_models.pytorch}},
  journal      = {GitHub repository},
  publisher    = {GitHub},
  title        = {Segmentation Models Pytorch},
  year         = 2019
}
@article{isensee2021nnu,
  author    = {Isensee, Fabian and Jaeger, Paul F and Kohl, Simon AA and Petersen, Jens and Maier-Hein, Klaus H},
  journal   = {Nature methods},
  number    = 2,
  pages     = {203--211},
  publisher = {Nature Publishing Group},
  title     = {nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation},
  volume    = 18,
  year      = 2021
}
@inproceedings{isensee2024nnu,
  author       = {Isensee, Fabian and Wald, Tassilo and Ulrich, Constantin and Baumgartner, Michael and Roy, Saikat and Maier-Hein, Klaus and Jaeger, Paul F},
  booktitle    = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
  organization = {Springer},
  pages        = {488--498},
  title        = {nnu-net revisited: A call for rigorous validation in 3d medical image segmentation},
  year         = 2024
}
@inproceedings{ji2019invariant,
  author    = {Ji, Xu and Henriques, Joao F and Vedaldi, Andrea},
  booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
  pages     = {9865--9874},
  title     = {Invariant information clustering for unsupervised image classification and segmentation},
  year      = 2019
}
@inproceedings{kapoor2021cell,
  author    = {Kapoor, Varun and Caraba{\~n}a, Claudia},
  booktitle = {Python in Science Conference},
  doi       = {10.25080/majora-1b6fd038-014},
  pages     = {154--161},
  title     = {Cell Tracking in 3D using deep learning segmentations},
  year      = 2021
}
@article{Kar2021.06.09.447748,
  abstract     = {Segmenting three dimensional microscopy images is essential for understanding phenomena like morphogenesis, cell division, cellular growth and genetic expression patterns. Recently, deep learning (DL) pipelines have been developed which claim to provide high accuracy segmentation of cellular images and are increasingly considered as the state-of-the-art for image segmentation problems. However, it remains difficult to define their relative performance as the concurrent diversity and lack of uniform evaluation strategies makes it difficult to know how their results compare. In this paper, we first made an inventory of the available DL methods for 3D segmentation. We next implemented and quantitatively compared a number of representative DL pipelines, alongside a highly efficient non-DL method named MARS. The DL methods were trained on a common dataset of 3D cellular confocal microscopy images. Their segmentation accuracies were also tested in the presence of different image artifacts. A new method for segmentation quality evaluation was adopted which isolates segmentation errors due to under/over segmentation. This is complemented with new visualization strategies that make interactive exploration of segmentation quality possible. Our analysis shows that the DL pipelines have very different levels of accuracy. Two of them show high performance, and offer clear advantages in terms of adaptability to new data.Competing Interest StatementThe authors have declared no competing interest.},
  author       = {Kar, Anuradha and Petit, Manuel and Refahi, Yassin and Cerutti, Guillaume and Godin, Christophe and Traas, Jan},
  doi          = {10.1101/2021.06.09.447748},
  elocation-id = {2021.06.09.447748},
  eprint       = {https://www.biorxiv.org/content/early/2021/06/10/2021.06.09.447748.full.pdf},
  journal      = {bioRxiv},
  publisher    = {Cold Spring Harbor Laboratory},
  title        = {Assessment of deep learning algorithms for 3D instance segmentation of confocal image datasets},
  url          = {https://www.biorxiv.org/content/early/2021/06/10/2021.06.09.447748},
  year         = 2021
}
@article{khatibi2021proposing,
  author    = {Khatibi, Toktam and Rezaei, Niloofar and Ataei Fashtami, Leila and Totonchi, Mehdi},
  doi       = {http://dx.doi.org/10.1111/srt.12920},
  journal   = {Skin Research and Technology},
  number    = 2,
  pages     = {126--137},
  publisher = {Wiley Online Library},
  title     = {Proposing a novel unsupervised stack ensemble of deep and conventional image segmentation (SEDCIS) method for localizing vitiligo lesions in skin images},
  volume    = 27,
  year      = 2021
}
@inproceedings{kim2019self,
  author    = {Kim, Dahun and Cho, Donghyeon and Kweon, In So},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  doi       = {https://doi.org/10.48550/arXiv.1811.09795},
  number    = {01},
  pages     = {8545--8552},
  title     = {Self-supervised video representation learning with space-time cubic puzzles},
  volume    = 33,
  year      = 2019
}
@misc{kim2024medivistamedicalvideosegmentation,
  archiveprefix = {arXiv},
  author        = {Sekeun Kim and Pengfei Jin and Cheng Chen and Kyungsang Kim and Zhiliang Lyu and Hui Ren and Sunghwan Kim and Zhengliang Liu and Aoxiao Zhong and Tianming Liu and Xiang Li and Quanzheng Li},
  eprint        = {2309.13539},
  primaryclass  = {eess.IV},
  title         = {MediViSTA: Medical Video Segmentation via Temporal Fusion SAM Adaptation for Echocardiography},
  url           = {https://arxiv.org/abs/2309.13539},
  year          = 2024
}
@article{kim2025medivista,
  author    = {Kim, Sekeun and Jin, Pengfei and Chen, Cheng and Kim, Kyungsang and Lyu, Zhiliang and Ren, Hui and Kim, Sunghwan and Liu, Zhengliang and Zhong, Aoxiao and Liu, Tianming and others},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  publisher = {IEEE},
  title     = {MediViSTA: Medical Video Segmentation via Temporal Fusion SAM Adaptation for Echocardiography},
  year      = 2025
}
@inproceedings{kirillov2017unified,
  author       = {Kirillov, Alexander and He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle    = {Computer Vision and Pattern Recognition Conference},
  doi          = {https://doi.org/10.48550/arXiv.2112.04603},
  organization = {CVPR},
  title        = {A unified architecture for instance and semantic segmentation},
  year         = 2017
}
@inproceedings{kirillov2023segment,
  archiveprefix = {arXiv},
  author        = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle     = {Proceedings of the IEEE/CVF international conference on computer vision},
  eprint        = {2304.02643},
  pages         = {4015--4026},
  primaryclass  = {cs.CV},
  title         = {Segment anything},
  url           = {https://arxiv.org/abs/2304.02643},
  year          = 2023
}
@inproceedings{koleilat2024medclip,
  author       = {Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming},
  booktitle    = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
  organization = {Springer},
  pages        = {643--653},
  title        = {MedCLIP-SAM: Bridging text and image towards universal medical image segmentation},
  year         = 2024
}
@article{koleilat2024medclipsamv2,
  author  = {Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming},
  journal = {arXiv preprint arXiv:2409.19483},
  title   = {MedCLIP-SAMv2: Towards Universal Text-Driven Medical Image Segmentation},
  year    = 2024
}
@inproceedings{kolesnikov2019revisiting,
  author    = {Kolesnikov, Alexander and Zhai, Xiaohua and Beyer, Lucas},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  doi       = {https://doi.org/10.48550/arXiv.1901.09005},
  pages     = {1920--1929},
  title     = {Revisiting self-supervised visual representation learning},
  year      = 2019
}
@article{krizhevsky2012imagenet,
  author  = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  doi     = {10.1145/3065386},
  journal = {Advances in neural information processing systems},
  title   = {Imagenet classification with deep convolutional neural networks},
  volume  = 25,
  year    = 2012
}
@article{Krois2021,
  author  = {Krois, Joachim and Garcia Cantu, Anselmo and Chaurasia, Akhilanand and Patil, Ranjitkumar and Chaudhari, Prabhat Kumar and Gaudin, Robert and Gehrung, Sascha and Schwendicke, Falk},
  day     = 17,
  doi     = {http://dx.doi.org/10.1038/s41598-021-85454-5},
  issn    = {2045-2322},
  journal = {Scientific Reports},
  month   = {Mar},
  number  = 1,
  pages   = 6102,
  title   = {Generalizability of deep learning models for dental image analysis},
  url     = {10.1038/s41598-021-85454-5},
  volume  = 11,
  year    = 2021
}
@article{lee2011muco,
  author    = {Lee, WL and Jayathilake, PG and Tan, Zhijun and Le, DV and Lee, HP and Khoo, BC},
  doi       = {https://doi.org/10.1016/j.compfluid.2011.05.016},
  journal   = {Computers \& Fluids},
  number    = 1,
  pages     = {214--221},
  publisher = {Elsevier},
  title     = {Muco-ciliary transport: effect of mucus viscosity, cilia beat frequency and cilia density},
  volume    = 49,
  year      = 2011
}
@article{lee2024foundation,
  author  = {Lee, Ho Hin and Gu, Yu and Zhao, Theodore and Xu, Yanbo and Yang, Jianwei and Usuyama, Naoto and Wong, Cliff and Wei, Mu and Landman, Bennett A and Huo, Yuankai and others},
  journal = {arXiv preprint arXiv:2401.07654},
  title   = {Foundation models for biomedical image segmentation: A survey},
  year    = 2024
}
@article{li2006one,
  author  = {Li, Fei-Fei and Fergus, Rob and Perona, Pietro and others},
  doi     = {http://dx.doi.org/10.1109/TPAMI.2006.79},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell},
  number  = 4,
  pages   = {594--611},
  title   = {One-shot learning of object categories},
  volume  = 28,
  year    = 2006
}
@inproceedings{li2024promise,
  author       = {Li, Hao and Liu, Han and Hu, Dewei and Wang, Jiacheng and Oguz, Ipek},
  booktitle    = {2024 IEEE International Symposium on Biomedical Imaging (ISBI)},
  organization = {IEEE},
  pages        = {1--5},
  title        = {Promise: Prompt-driven 3d medical image segmentation using pretrained image foundation models},
  year         = 2024
}
@article{liu2014mslrr,
  author    = {Liu, Xiaobai and Xu, Qian and Ma, Jiayi and Jin, Hai and Zhang, Yanduo},
  journal   = {IEEE transactions on image processing},
  number    = 5,
  pages     = {2159--2167},
  publisher = {IEEE},
  title     = {MsLRR: A unified multiscale low-rank representation for image segmentation},
  volume    = 23,
  year      = 2014
}
@inproceedings{liu2016ssd,
  author       = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle    = {Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  organization = {Springer},
  pages        = {21--37},
  title        = {Ssd: Single shot multibox detector},
  year         = 2016
}
@article{liu2022multi,
  author    = {Liu, Ye and Wagner, Sophia J and Peng, Tingying},
  journal   = {Journal of Imaging},
  number    = 3,
  pages     = 71,
  publisher = {MDPI},
  title     = {Multi-modality microscopy image style augmentation for nuclei segmentation},
  volume    = 8,
  year      = 2022
}
@article{lu2018stacked,
  author  = {Lu, Charles and Marx, Maurice and Zahid, Maliha and Lo, Cecilia W and Chennubhotla, Chakra and Quinn, Shannon P},
  doi     = {https://doi.org/10.48550/arXiv.1803.07534},
  journal = {arXiv preprint arXiv:1803.07534},
  title   = {Stacked Neural Networks for end-to-end ciliary motion analysis},
  year    = 2018
}
% ##################################################################################


# Feel free to delete these first few references, which are specific to the template:
@article{ma2023towards,
  author    = {Ma, Jun and Wang, Bo},
  journal   = {Nature Methods},
  number    = 7,
  pages     = {953--955},
  publisher = {Nature Publishing Group US New York},
  title     = {Towards foundation models of biological image segmentation},
  volume    = 20,
  year      = 2023
}
@article{ma2024segment,
  author    = {Ma, Jun and Kim, Sumin and Li, Feifei and Baharoon, Mohammed and Asakereh, Reza and Lyu, Hongwei and Wang, Bo},
  journal   = {arXiv preprint arXiv:2408.03322},
  number    = 1,
  pages     = 654,
  publisher = {Nature Publishing Group UK London},
  title     = {Segment anything in medical images and videos: Benchmark and deployment},
  volume    = 15,
  year      = 2024
}
@inproceedings{mahendran2019cross,
  author       = {Mahendran, Aravindh and Thewlis, James and Vedaldi, Andrea},
  booktitle    = {Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part V 14},
  doi          = {https://doi.org/10.48550/arXiv.1807.05636},
  organization = {Springer},
  pages        = {99--116},
  title        = {Cross pixel optical-flow similarity for self-supervised learning},
  year         = 2019
}
@article{maier2018rankings,
  author    = {Maier-Hein, Lena and Eisenmann, Matthias and Reinke, Annika and Onogur, Sinan and Stankovic, Marko and Scholz, Patrick and Arbel, Tal and Bogunovic, Hrvoje and Bradley, Andrew P and Carass, Aaron and others},
  journal   = {Nature communications},
  number    = 1,
  pages     = 5217,
  publisher = {Nature Publishing Group UK London},
  title     = {Why rankings of biomedical image analysis competitions should be interpreted with care},
  volume    = 9,
  year      = 2018
}
@article{mavska2023cell,
  author    = {Ma{\v{s}}ka, Martin and Ulman, Vladim{\'\i}r and Delgado-Rodriguez, Pablo and G{\'o}mez-de-Mariscal, Estibaliz and Ne{\v{c}}asov{\'a}, Tereza and Guerrero Pe{\~n}a, Fidel A and Ren, Tsang Ing and Meyerowitz, Elliot M and Scherr, Tim and L{\"o}ffler, Katharina and others},
  journal   = {Nature Methods},
  number    = 7,
  pages     = {1010--1020},
  publisher = {Nature Publishing Group US New York},
  title     = {The cell tracking challenge: 10 years of objective benchmarking},
  volume    = 20,
  year      = 2023
}
@article{mazurowski2023segment,
  author    = {Mazurowski, Maciej A and Dong, Haoyu and Gu, Hanxue and Yang, Jichen and Konz, Nicholas and Zhang, Yixin},
  journal   = {Medical Image Analysis},
  pages     = 102918,
  publisher = {Elsevier},
  title     = {Segment anything model for medical image analysis: an experimental study},
  volume    = 89,
  year      = 2023
}
@inproceedings{miller2000learning,
  author       = {Miller, Erik G and Matsakis, Nicholas E and Viola, Paul A},
  booktitle    = {Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)},
  doi          = {https://doi.org/10.1109/CVPR.2000.855856},
  organization = {IEEE},
  pages        = {464--471},
  title        = {Learning from one example through shared densities on transforms},
  volume       = 1,
  year         = 2000
}
@article{na2024segment,
  author  = {Na, Saiyang and Guo, Yuzhi and Jiang, Feng and Ma, Hehuan and Huang, Junzhou},
  journal = {arXiv preprint arXiv:2401.13220},
  title   = {Segment any cell: A sam-based auto-prompting fine-tuning framework for nuclei segmentation},
  year    = 2024
}
@inproceedings{nam2016learning,
  author    = {Nam, Hyeonseob and Han, Bohyung},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4293--4302},
  title     = {Learning multi-domain convolutional neural networks for visual tracking},
  year      = 2016
}
@inproceedings{NEURIPS2019_eb1e7832,
  author    = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
  booktitle = {Advances in Neural Information Processing Systems},
  doi       = {https://doi.org/10.48550/arXiv.1902.07208},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Transfusion: Understanding Transfer Learning for Medical Imaging},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2019/file/eb1e78328c46506b46a4ac4a1e378b91-Paper.pdf},
  volume    = 32,
  year      = 2019
}
@inproceedings{oliveira2022domain,
  author       = {Oliveira, Hugo and Cesar, Roberto M and Gama, Pedro HT and Dos Santos, Jefersson A},
  booktitle    = {2022 35th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
  organization = {IEEE},
  pages        = {288--293},
  title        = {Domain generalization in medical image segmentation via meta-learners},
  volume       = 1,
  year         = 2022
}
@article{oord2018representation,
  author  = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal = {arXiv preprint arXiv:1807.03748},
  title   = {Representation learning with contrastive predictive coding},
  year    = 2018
}
@article{plantseg,
  abstract     = {Quantitative analysis of plant and animal morphogenesis requires accurate segmentation of individual cells in volumetric images of growing organs. In the last years, deep learning has provided robust automated algorithms that approach human performance, with applications to bio-image analysis now starting to emerge. Here, we present PlantSeg, a pipeline for volumetric segmentation of plant tissues into cells. PlantSeg employs a convolutional neural network to predict cell boundaries and graph partitioning to segment cells based on the neural network predictions. PlantSeg was trained on fixed and live plant organs imaged with confocal and light sheet microscopes. PlantSeg delivers accurate results and generalizes well across different tissues, scales, acquisition settings even on non plant samples. We present results of PlantSeg applications in diverse developmental contexts. PlantSeg is free and open-source, with both a command line and a user-friendly graphical interface.},
  article_type = {journal},
  author       = {Wolny, Adrian and Cerrone, Lorenzo and Vijayan, Athul and Tofanelli, Rachele and Barro, Amaya Vilches and Louveaux, Marion and Wenzl, Christian and Strauss, Sören and Wilson-Sánchez, David and Lymbouridou, Rena and Steigleder, Susanne S and Pape, Constantin and Bailoni, Alberto and Duran-Nebreda, Salva and Bassel, George W and Lohmann, Jan U and Tsiantis, Miltos and Hamprecht, Fred A and Schneitz, Kay and Maizel, Alexis and Kreshuk, Anna},
  citation     = {eLife 2020;9:e57613},
  doi          = {10.7554/eLife.57613},
  editor       = {Hardtke, Christian S and Bergmann, Dominique C and Bergmann, Dominique C and Graeff, Moritz},
  issn         = {2050-084X},
  journal      = {eLife},
  keywords     = {instance segmentation, cell segmentation, deep learning, image analysis},
  month        = {jul},
  pages        = {e57613},
  pub_date     = {2020-07-29},
  publisher    = {eLife Sciences Publications, Ltd},
  title        = {Accurate and versatile 3D segmentation of plant tissues at cellular resolution},
  url          = {https://doi.org/10.7554/eLife.57613},
  volume       = 9,
  year         = 2020
}
@article{quinn2015automated,
  author    = {Quinn, Shannon P and Zahid, Maliha J and Durkin, John R and Francis, Richard J and Lo, Cecilia W and Chennubhotla, S Chakra},
  doi       = {http://dx.doi.org/10.1126/scitranslmed.aaa1233},
  journal   = {Science translational medicine},
  number    = 299,
  pages     = {299ra124--299ra124},
  publisher = {American Association for the Advancement of Science},
  title     = {Automated identification of abnormal respiratory ciliary motion in nasal biopsies},
  volume    = 7,
  year      = 2015
}
@inproceedings{radford2021learning,
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle    = {International conference on machine learning},
  organization = {PmLR},
  pages        = {8748--8763},
  title        = {Learning transferable visual models from natural language supervision},
  year         = 2021
}
@inproceedings{rakic2024tyche,
  author    = {Rakic, Marianne and Wong, Hallee E and Ortiz, Jose Javier Gonzalez and Cimini, Beth A and Guttag, John V and Dalca, Adrian V},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {11159--11173},
  title     = {Tyche: Stochastic in-context learning for medical image segmentation},
  year      = 2024
}
@article{ravi2024sam,
  author  = {Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and others},
  journal = {arXiv preprint arXiv:2408.00714},
  title   = {Sam 2: Segment anything in images and videos},
  year    = 2024
}
@inproceedings{ronneberger2015u,
  author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle    = {Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  doi          = {10.48550/arXiv.1505.04597},
  organization = {Springer},
  pages        = {234--241},
  title        = {U-net: Convolutional networks for biomedical image segmentation},
  year         = 2015
}
}
@inproceedings{ryali2023hiera,
  author       = {Ryali, Chaitanya and Hu, Yuan-Ting and Bolya, Daniel and Wei, Chen and Fan, Haoqi and Huang, Po-Yao and Aggarwal, Vaibhav and Chowdhury, Arkabandhu and Poursaeed, Omid and Hoffman, Judy and others},
  booktitle    = {International conference on machine learning},
  organization = {PMLR},
  pages        = {29441--29454},
  title        = {Hiera: A hierarchical vision transformer without the bells-and-whistles},
  year         = 2023
}
@article{saadatnia2012review,
  author    = {Saadatnia, Geita and Golkar, Majid},
  doi       = {10.3109/00365548.2012.693197},
  journal   = {Scandinavian journal of infectious diseases},
  number    = 11,
  pages     = {805--814},
  publisher = {Taylor \& Francis},
  title     = {A review on human toxoplasmosis},
  volume    = 44,
  year      = 2012
}
@article{Sandfort2019,
  author  = {Sandfort, Veit and Yan, Ke and Pickhardt, Perry J. and Summers, Ronald M.},
  day     = 15,
  doi     = {https://doi.org/10.1016/j.imu.2021.100779},
  issn    = {2045-2322},
  journal = {Scientific Reports},
  month   = {Nov},
  number  = 1,
  pages   = 16884,
  title   = {Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks},
  volume  = 9,
  year    = 2019
}
@article{Sanford2020-yg,
  address  = {United States},
  author   = {Sanford, Thomas H and Zhang, Ling and Harmon, Stephanie A and Sackett, Jonathan and Yang, Dong and Roth, Holger and Xu, Ziyue and Kesani, Deepak and Mehralivand, Sherif and Baroni, Ronaldo H and Barrett, Tristan and Girometti, Rossano and Oto, Aytekin and Purysko, Andrei S and Xu, Sheng and Pinto, Peter A and Xu, Daguang and Wood, Bradford J and Choyke, Peter L and Turkbey, Baris},
  doi      = {http://dx.doi.org/10.2214/AJR.19.22347},
  journal  = {AJR Am J Roentgenol},
  keywords = {artificial intelligence; prostate MRI; segmentation},
  language = {en},
  month    = {oct},
  number   = 6,
  pages    = {1403--1410},
  title    = {Data Augmentation and Transfer Learning to Improve Generalizability of an Automated Prostate Segmentation Model},
  volume   = 215,
  year     = 2020
}
@article{settles2009active,
  author    = {Settles, Burr},
  publisher = {University of Wisconsin-Madison Department of Computer Sciences},
  title     = {Active learning literature survey},
  year      = 2009
}
@software{sofroniew_nicholas_2022_6598542,
  author    = {Sofroniew, Nicholas and Lambert, Talley and Evans, Kira and Nunez-Iglesias, Juan and Bokota, Grzegorz and Winston, Philip and Peña-Castellanos, Gonzalo and Yamauchi, Kevin and Bussonnier, Matthias and Doncila Pop, Draga and Can Solak, Ahmet and Liu, Ziyang and Wadhwa, Pam and Burt, Alister and Buckley, Genevieve and Sweet, Andrew and Migas, Lukasz and Hilsenstein, Volker and Gaifas, Lorenzo and Bragantini, Jordão and Rodríguez-Guerra, Jaime and Muñoz, Hector and Freeman, Jeremy and Boone, Peter and Lowe, Alan and Gohlke, Christoph and Royer, Loic and PIERRÉ, Andrea and Har-Gil, Hagai and McGovern, Abigail},
  doi       = {10.5281/zenodo.6598542},
  month     = {may},
  note      = {{If you use this software, please cite it using these metadata.}},
  publisher = {Zenodo},
  title     = {{napari: a multi-dimensional image viewer for Python}},
  url       = {https://doi.org/10.5281/zenodo.6598542},
  version   = {v0.4.16},
  year      = 2022
}
@article{sofroniew2022napari,
  author  = {Sofroniew, Nicholas and Lambert, Talley and Evans, Kira and Nunez-Iglesias, Juan and Bokota, Grzegorz and Winston, Philip and Pe{\~n}a-Castellanos, Gonzalo and Yamauchi, Kevin and Bussonnier, Matthias and Pop, D Doncila and others},
  journal = {Zenodo},
  title   = {napari: a multi-dimensional image viewer for Python},
  year    = 2022
}
@article{stringer2021cellpose,
  author    = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
  doi       = {10.1101/2020.02.02.931238},
  journal   = {Nature methods},
  number    = 1,
  pages     = {100--106},
  publisher = {Nature Publishing Group},
  title     = {Cellpose: a generalist algorithm for cellular segmentation},
  volume    = 18,
  year      = 2021
}
@inproceedings{tan2019efficientnet,
  author       = {Tan, Mingxing and Le, Quoc},
  booktitle    = {International conference on machine learning},
  organization = {PMLR},
  pages        = {6105--6114},
  title        = {Efficientnet: Rethinking model scaling for convolutional neural networks},
  year         = 2019
}
@article{TgPHIL1,
  author  = {Leung, Jacqueline and Rould, Mark and Konradt, Christoph and Hunter, Christopher and Ward, Gary},
  doi     = {10.1371/journal.pone.0085763},
  journal = {PloS one},
  month   = {01},
  pages   = {e85763},
  title   = {Disruption of TgPHIL1 Alters Specific Parameters of Toxoplasma gondii Motility Measured in a Quantitative, Three-Dimensional Live Motility Assay},
  volume  = 9,
  year    = 2014
}
@article{TINEVEZ201780,
  author   = {Jean-Yves Tinevez and Nick Perry and Johannes Schindelin and Genevieve M. Hoopes and Gregory D. Reynolds and Emmanuel Laplantine and Sebastian Y. Bednarek and Spencer L. Shorte and Kevin W. Eliceiri},
  doi      = {https://doi.org/10.1016/j.ymeth.2016.09.016},
  issn     = {1046-2023},
  journal  = {Methods},
  keywords = {Single-particle tracking, Phototoxicity, Clathin-mediated endocytosis, Image analysis, Open-source software, Microscopy},
  note     = {Image Processing for Biologists},
  pages    = {80--90},
  title    = {TrackMate: An open and extensible platform for single-particle tracking},
  url      = {https://www.sciencedirect.com/science/article/pii/S1046202316303346},
  volume   = 115,
  year     = 2017
}
@inproceedings{vaezi2022novel,
  author    = {Vaezi, Seyed Alireza and Orlando, Gianni and Fazli, Mojtaba Sedigh and Ward, Gary E and Moreno, Silvia NJ and Quinn, Shannon},
  booktitle = {SciPy},
  doi       = {https://doi.org/10.25080/majora-212e5952-009},
  pages     = {60--63},
  title     = {A Novel Pipeline for Cell Instance Segmentation, Tracking and Motility Classification of Toxoplasma Gondii in 3D Space.},
  year      = 2022
}
@article{vaezi2024training,
  author  = {Vaezi, Seyed Alireza and Quinn, Shannon},
  journal = {Proceedings of the 23nd},
  title   = {Training a Supervised Cilia Segmentation Model from Self-Supervision},
  year    = 2024
}
@article{van2001art,
  author    = {Van Dyk, David A and Meng, Xiao-Li},
  doi       = {http://dx.doi.org/10.1198/10618600152418584},
  journal   = {Journal of Computational and Graphical Statistics},
  number    = 1,
  pages     = {1--50},
  publisher = {Taylor \& Francis},
  title     = {The art of data augmentation},
  volume    = 10,
  year      = 2001
}
@article{van2020survey,
  author    = {Van Engelen, Jesper E and Hoos, Holger H},
  doi       = {http://dx.doi.org/10.1007/s10994-019-05855-6},
  journal   = {Machine learning},
  number    = 2,
  pages     = {373--440},
  publisher = {Springer},
  title     = {A survey on semi-supervised learning},
  volume    = 109,
  year      = 2020
}
@article{vicar2019cell,
  author    = {Vicar, Tomas and Balvan, Jan and Jaros, Josef and Jug, Florian and Kolar, Radim and Masarik, Michal and Gumulec, Jaromir},
  journal   = {BMC bioinformatics},
  pages     = {1--25},
  publisher = {Springer},
  title     = {Cell segmentation methods for label-free contrast microscopy: review and comprehensive comparison},
  volume    = 20,
  year      = 2019
}
@article{von2021democratising,
  author    = {von Chamier, Lucas and Laine, Romain F and Jukkala, Johanna and Spahn, Christoph and Krentzel, Daniel and Nehme, Elias and Lerche, Martina and Hern{\'a}ndez-P{\'e}rez, Sara and Mattila, Pieta K and Karinou, Eleni and others},
  doi       = {10.1038/s41467-021-22518-0},
  journal   = {Nature communications},
  number    = 1,
  pages     = {1--18},
  publisher = {Nature Publishing Group},
  title     = {Democratising deep learning for microscopy with ZeroCostDL4Mic},
  volume    = 12,
  year      = 2021
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%    AIM 3    %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{wang2021annotation,
  author    = {Wang, Shanshan and Li, Cheng and Wang, Rongpin and Liu, Zaiyi and Wang, Meiyun and Tan, Hongna and Wu, Yaping and Liu, Xinfeng and Sun, Hui and Yang, Rui and others},
  journal   = {Nature communications},
  number    = 1,
  pages     = 5915,
  publisher = {Nature Publishing Group UK London},
  title     = {Annotation-efficient deep learning for automatic medical image segmentation},
  volume    = 12,
  year      = 2021
}
@inproceedings{Weigert_2020,
  author    = {Martin Weigert and Uwe Schmidt and Robert Haase and Ko Sugawara and Gene Myers},
  booktitle = {2020 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
  doi       = {10.1109/wacv45572.2020.9093435},
  month     = {mar},
  publisher = {{IEEE}},
  title     = {Star-convex Polyhedra for 3D Object Detection and Segmentation in Microscopy},
  url       = {https://doi.org/10.1109%2Fwacv45572.2020.9093435},
  year      = 2020
}
@article{Wen2021-bn,
  author    = {Wen, Chentao and Miura, Takuya and Voleti, Venkatakaushik and Yamaguchi, Kazushi and Tsutsumi, Motosuke and Yamamoto, Kei and Otomo, Kohei and Fujie, Yukako and Teramoto, Takayuki and Ishihara, Takeshi and Aoki, Kazuhiro and Nemoto, Tomomi and Hillman, Elizabeth Mc and Kimura, Koutarou D},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  doi       = {10.7554/eLife.59187},
  journal   = {Elife},
  keywords  = {C. elegans; bioimaging; cell tracking; computational biology; deep learning; neuroscience; quantitative biology; systems biology; zebrafish},
  month     = {mar},
  publisher = {eLife Sciences Publications, Ltd},
  title     = {{3DeeCellTracker}, a deep learning-based pipeline for segmenting and tracking cells in {3D} time lapse images},
  url       = {https://doi.org/10.7554/eLife.59187},
  volume    = 10,
  year      = 2021
}
@article{weng2021inet,
  author    = {Weng, Weihao and Zhu, Xin},
  journal   = {Ieee Access},
  pages     = {16591--16603},
  publisher = {IEEE},
  title     = {INet: convolutional networks for biomedical image segmentation},
  volume    = 9,
  year      = 2021
}
@article{wu2023medical,
  author  = {Wu, Junde and Ji, Wei and Liu, Yuanpei and Fu, Huazhu and Xu, Min and Xu, Yanwu and Jin, Yueming},
  journal = {arXiv preprint arXiv:2304.12620},
  title   = {Medical sam adapter: Adapting segment anything model for medical image segmentation},
  year    = 2023
}
@article{xia2017w,
  author  = {Xia, Xide and Kulis, Brian},
  journal = {arXiv preprint arXiv:1711.08506},
  title   = {W-net: A deep model for fully unsupervised image segmentation},
  year    = 2017
}
@article{YAKIMOVICH2021100383,
  abstract = {Summary Recent advances in biomedical machine learning demonstrate great potential for data-driven techniques in health care and biomedical research. However, this potential has thus far been hampered by both the scarcity of annotated data in the biomedical domain and the diversity of the domain's subfields. While unsupervised learning is capable of finding unknown patterns in the data by design, supervised learning requires human annotation to achieve the desired performance through training. With the latter performing vastly better than the former, the need for annotated datasets is high, but they are costly and laborious to obtain. This review explores a family of approaches existing between the supervised and the unsupervised problem setting. The goal of these algorithms is to make more efficient use of the available labeled data. The advantages and limitations of each approach are addressed and perspectives are provided.},
  author   = {Artur Yakimovich and Anaël Beaugnon and Yi Huang and Elif Ozkirimli},
  doi      = {https://doi.org/10.1016/j.patter.2021.100383},
  issn     = {2666-3899},
  journal  = {Patterns},
  keywords = {machine learning, data labeling, data value, active learning, self-supervised learning, semi-supervised learning, data annotation, zero-shot learning},
  number   = 12,
  pages    = 100383,
  title    = {Labels in a haystack: Approaches beyond supervised learning in biomedical applications},
  url      = {https://www.sciencedirect.com/science/article/pii/S2666389921002506},
  volume   = 2,
  year     = 2021
}
@article{yan2024biomedical,
  author  = {Yan, Zhiling and Sun, Weixiang and Zhou, Rong and Yuan, Zhengqing and Zhang, Kai and Li, Yiwei and Liu, Tianming and Li, Quanzheng and Li, Xiang and He, Lifang and others},
  journal = {arXiv preprint arXiv:2408.03286},
  title   = {Biomedical sam 2: Segment anything in biomedical images and videos},
  year    = 2024
}
@article{ye2024hi,
  author    = {Ye, Maoyuan and Zhang, Jing and Liu, Juhua and Liu, Chenyu and Yin, Baocai and Liu, Cong and Du, Bo and Tao, Dacheng},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {IEEE},
  title     = {Hi-sam: Marrying segment anything model for hierarchical text segmentation},
  year      = 2024
}
@article{yi2019generative,
  author    = {Yi, Xin and Walia, Ekta and Babyn, Paul},
  doi       = {https://doi.org/10.48550/arXiv.1809.07294},
  journal   = {Medical image analysis},
  pages     = 101552,
  publisher = {Elsevier},
  title     = {Generative adversarial network in medical imaging: A review},
  volume    = 58,
  year      = 2019
}
@inproceedings{zain2020towards,
  author    = {Zain, Meekail and Rao, Sonia and Safir, Nathan and Wyner, Quinn and Humphrey, Isabella and Eldridge, Alex and Li, Chenxiao and AlAila, BahaaEddin and Quinn, Shannon},
  booktitle = {Proceedings of the Python in Science Conference},
  doi       = {http://dx.doi.org/10.25080/Majora-342d178e-017},
  title     = {Towards an unsupervised spatiotemporal representation of cilia video using a modular generative pipeline},
  year      = 2020
}
@inproceedings{zain2022low,
  author    = {Zain, Meekail and Miller, Eric and Quinn, Shannon and Lo, Cecilia},
  booktitle = {Proceedings of the Python in Science Conference},
  doi       = {https://doi.org/10.25080/majora-212e5952-026},
  title     = {Low Level Feature Extraction for Cilia Segmentation},
  year      = 2022
}
@article{zhang2023biomedclip,
  author  = {Zhang, Sheng and Xu, Yanbo and Usuyama, Naoto and Xu, Hanwen and Bagga, Jaspreet and Tinn, Robert and Preston, Sam and Rao, Rajesh and Wei, Mu and Valluri, Naveen and others},
  journal = {arXiv preprint arXiv:2303.00915},
  title   = {Biomedclip: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs},
  year    = 2023
}
@article{zhang2023segment,
  author  = {Zhang, Lian and Liu, Zhengliang and Zhang, Lu and Wu, Zihao and Yu, Xiaowei and Holmes, Jason and Feng, Hongying and Dai, Haixing and Li, Xiang and Li, Quanzheng and others},
  journal = {arXiv preprint arXiv:2306.11730},
  title   = {Segment anything model (sam) for radiation oncology},
  year    = 2023
}
@article{zhang2024evf,
  author  = {Zhang, Yuxuan and Cheng, Tianheng and Hu, Rui and Liu, Lei and Liu, Heng and Ran, Longjin and Chen, Xiaoxin and Liu, Wenyu and Wang, Xinggang},
  journal = {arXiv preprint arXiv:2406.20076},
  title   = {Evf-sam: Early vision-language fusion for text-prompted segment anything model},
  year    = 2024
}
@article{zhao2023one,
  author  = {Zhao, Ziheng and Zhang, Yao and Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal = {arXiv preprint arXiv:2312.17183},
  title   = {One model to rule them all: Towards universal segmentation for medical images with text prompts},
  year    = 2023
}
@article{zhou2019review,
  author    = {Zhou, Tongxue and Ruan, Su and Canu, St{\'e}phane},
  journal   = {Array},
  pages     = 100004,
  publisher = {Elsevier},
  title     = {A review: Deep learning for medical image segmentation using multi-modality fusion},
  volume    = 3,
  year      = 2019
}
